{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ydk08m5IF7VW"
   },
   "source": [
    "# Big Data\n",
    "# Assignment 2\n",
    "## 202318042\n",
    "\n",
    "To implement a document similarity search using TF-IDF\n",
    "(Term Frequency-Inverse Document Frequency) in Python. You will build a system that,\n",
    "given a document, retrieves other documents based on their similarity to the input\n",
    "document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "z73zUkrC3pdZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfspZUDwGJAk"
   },
   "source": [
    "## Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ppqxdHBx3Za8"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KY2YA5m16VU9"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Tiwxirma6m00"
   },
   "outputs": [],
   "source": [
    "data=fetch_20newsgroups(subset=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "a06R2vhw7IRG"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "x = vectorizer.fit_transform(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TXErNbc-7g9G",
    "outputId": "fb4df9b9-2bfa-4dfb-d387-4a001db0b5c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65-M2VxN_M9x",
    "outputId": "3ad74ba4-9eef-413c-afb5-0c69d1b11833"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 86580)\t0.13157118714240987\n",
      "  (0, 128420)\t0.04278499079283093\n",
      "  (0, 35983)\t0.03770448563619875\n",
      "  (0, 35187)\t0.09353930598317124\n",
      "  (0, 66098)\t0.09785515708314481\n",
      "  (0, 114428)\t0.05511105154696676\n",
      "  (0, 78955)\t0.05989856888061599\n",
      "  (0, 94362)\t0.055457031390147224\n",
      "  (0, 76722)\t0.06908779999621749\n",
      "  (0, 57308)\t0.1558717009157704\n",
      "  (0, 62221)\t0.02921527992427867\n",
      "  (0, 128402)\t0.05922294083277842\n",
      "  (0, 67156)\t0.07313443922740179\n",
      "  (0, 123989)\t0.08207027465330353\n",
      "  (0, 90252)\t0.031889368795417566\n",
      "  (0, 63363)\t0.08342748387969037\n",
      "  (0, 78784)\t0.0633940918806495\n",
      "  (0, 96144)\t0.10826904490745741\n",
      "  (0, 128026)\t0.060622095889758885\n",
      "  (0, 109271)\t0.10844724822064673\n",
      "  (0, 51730)\t0.09714744057976722\n",
      "  (0, 86001)\t0.07000411445838192\n",
      "  (0, 83256)\t0.08844382496462173\n",
      "  (0, 113986)\t0.17691750674853082\n",
      "  (0, 37565)\t0.03431760442478462\n",
      "  :\t:\n",
      "  (11313, 87626)\t0.041237139601784885\n",
      "  (11313, 30044)\t0.03581554412880591\n",
      "  (11313, 76377)\t0.0635841806495367\n",
      "  (11313, 119714)\t0.05924995560199499\n",
      "  (11313, 47982)\t0.04878764010149914\n",
      "  (11313, 28146)\t0.04703946070749562\n",
      "  (11313, 88363)\t0.13916610283479094\n",
      "  (11313, 56283)\t0.026074886321515986\n",
      "  (11313, 111695)\t0.08039375842219382\n",
      "  (11313, 90252)\t0.03304599951634829\n",
      "  (11313, 51730)\t0.10067098834752665\n",
      "  (11313, 68766)\t0.026413823187147637\n",
      "  (11313, 89860)\t0.029615670644273114\n",
      "  (11313, 80638)\t0.0409862722594402\n",
      "  (11313, 4605)\t0.06562288156075427\n",
      "  (11313, 76032)\t0.019916554974882542\n",
      "  (11313, 89362)\t0.022525659920776243\n",
      "  (11313, 90379)\t0.020651681778766563\n",
      "  (11313, 64095)\t0.03670564487644039\n",
      "  (11313, 95162)\t0.035721664777432695\n",
      "  (11313, 87620)\t0.03696568532482317\n",
      "  (11313, 111322)\t0.019851534178948714\n",
      "  (11313, 85354)\t0.03831068303611253\n",
      "  (11313, 50527)\t0.056595152440003904\n",
      "  (11313, 56979)\t0.03970306835789743\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4SvQCMvGNvQ"
   },
   "source": [
    "## Q2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EG11Bp9Eckue"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgYzvCiH_PZW",
    "outputId": "e100fad0-4c9c-45bb-b12a-5c525bf375b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0817948]]\n"
     ]
    }
   ],
   "source": [
    "cosine_sim = cosine_similarity(x[13], x[5])\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbv13peerX4o"
   },
   "source": [
    "## Q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7LkEvGEWjqmD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.65688607, 0.60005376, 0.91852362])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string, nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#import sparse_dot_topn.sparse_dot_topn as ct\n",
    "import re\n",
    "\n",
    "documents = 'the cat in the hat','the catty ate the hat','the cat wants the cats hat','the cat cats in the hat'\n",
    "\n",
    "def ngrams(string, n=2):\n",
    "    string = re.sub(r'[,-./]|\\sBD',r'', string)\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "\n",
    "TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, analyzer=ngrams, stop_words='english')\n",
    "tfidf_matrix = TfidfVec.fit_transform(documents)\n",
    "\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "cosine_similarities = linear_kernel(tfidf_matrix[0:1], tfidf_matrix).flatten()\n",
    "\n",
    "related_docs_indices = cosine_similarities.argsort()[:-5:-1]\n",
    "\n",
    "cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CHiXoBGZoMRA"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"original df col\", \"most similar doc\", \"similarity%\"])\n",
    "for i in range(len(documents)):\n",
    "    cosine_similarities = linear_kernel(tfidf_matrix[i:i+1], tfidf_matrix).flatten()\n",
    "    # make pairs of (index, similarity)\n",
    "    cosine_similarities = list(enumerate(cosine_similarities))\n",
    "    # delete the cosine similarity with itself\n",
    "    cosine_similarities.pop(i)\n",
    "    # get the tuple with max similarity\n",
    "    most_similar, similarity = max(cosine_similarities, key=lambda t:t[1])\n",
    "    df.loc[len(df)] = [documents[i], documents[most_similar], similarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original df col</th>\n",
       "      <th>most similar doc</th>\n",
       "      <th>similarity%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the cat in the hat</td>\n",
       "      <td>the cat cats in the hat</td>\n",
       "      <td>0.918524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the catty ate the hat</td>\n",
       "      <td>the cat in the hat</td>\n",
       "      <td>0.656886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the cat wants the cats hat</td>\n",
       "      <td>the cat cats in the hat</td>\n",
       "      <td>0.780332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the cat cats in the hat</td>\n",
       "      <td>the cat in the hat</td>\n",
       "      <td>0.918524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              original df col         most similar doc  similarity%\n",
       "0          the cat in the hat  the cat cats in the hat     0.918524\n",
       "1       the catty ate the hat       the cat in the hat     0.656886\n",
       "2  the cat wants the cats hat  the cat cats in the hat     0.780332\n",
       "3     the cat cats in the hat       the cat in the hat     0.918524"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
